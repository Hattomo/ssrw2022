{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55384fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from language_model import PhonemeLangModel\n",
    "from phoneme_dataset import PhonemeDataset, collate_fn, dataset_spliter, MaskedPhonemeDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from trainer_phoneme import Trainer, MaskedTrainer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e079e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "dict_path = 'data/label.pkl'\n",
    "labels_path = 'data/phoneme.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602ce309",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dict_path, 'rb') as f:\n",
    "    phone_dict = pickle.load(f)\n",
    "with open(labels_path, 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    datas = list(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459081e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_file = './data/phoneme_data.txt'\n",
    "with open(additional_file, 'r') as f:\n",
    "    sentenses = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3656938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = 'data/phoneme_dict.json'\n",
    "with open(dict_path, 'r') as f:\n",
    "    phone_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2325ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [s.replace('\\n', '').split() for s in sentenses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c66840b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 730554 valid: 243518 test: 243518\n"
     ]
    }
   ],
   "source": [
    "datas_train, datas_valid, datas_test = dataset_spliter(datas)\n",
    "dataset_train = MaskedPhonemeDataset(phone_dict, datas_train)\n",
    "dataset_valid = MaskedPhonemeDataset(phone_dict, datas_valid)\n",
    "dataset_test  = MaskedPhonemeDataset(phone_dict, datas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e02fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              shuffle=True,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              collate_fn=collate_fn,\n",
    "                              drop_last=True)\n",
    "dataloader_valid = DataLoader(dataset_valid,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              collate_fn=collate_fn,\n",
    "                              drop_last=True)\n",
    "dataloader_test  = DataLoader(dataset_test,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              collate_fn=collate_fn,\n",
    "                              drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d72b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhonemeLangModel().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48580b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4b3b10160c44e1ac994ac639e3ea41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028bf1e9bd424a939972af2cf68aa8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2853 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.59 GiB (GPU 0; 11.00 GiB total capacity; 3.52 GiB already allocated; 1.32 GiB free; 7.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MaskedTrainer(model, dataloader_train, dataloader_valid, criterion, optimizer)\n\u001b[1;32m----> 4\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(EPOCHS, BATCH_SIZE)\n",
      "File \u001b[1;32mD:\\Aoyama\\hattori\\ssrw2022\\trainer_phoneme.py:220\u001b[0m, in \u001b[0;36mMaskedTrainer.train\u001b[1;34m(self, epochs, batch_size, hidden_dim, mask_ratio)\u001b[0m\n\u001b[0;32m    218\u001b[0m     train_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# print(f'loss: {loss}    acc: {acc}')\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# 検証\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ssrw\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ssrw\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.59 GiB (GPU 0; 11.00 GiB total capacity; 3.52 GiB already allocated; 1.32 GiB free; 7.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainer = MaskedTrainer(model, dataloader_train, dataloader_valid, criterion, optimizer)\n",
    "trainer.train(EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './lstm_lang_model.pth'\n",
    "torch.save(model.to('cpu').state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ed603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss_dict = {'train_loss': trainer.train_loss_list,\n",
    "             'valid_loss': trainer.valid_loss_list,\n",
    "             'train_acc': trainer.train_acc_list,\n",
    "             'valid_acc': trainer.valid_acc_list}\n",
    "df = pd.DataFrame(loss_dict)\n",
    "df.to_csv('./lstm_lang_model_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./lstm_lang_model_losses.csv')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax1 = plt.subplots()\n",
    "x = np.array([i for i in range(EPOCHS)])\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.plot(x, df['train_loss'], label='train_loss')\n",
    "ax1.plot(x, df['valid_loss'], label='valid_loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, df['train_acc'], label='train_acc')\n",
    "ax2.plot(x, df['valid_acc'], label='valid_acc')\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_ylabel('loss')\n",
    "ax2.set_ylabel('acc')\n",
    "plt.savefig('./graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40000106",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './lstm_lang_model.pth'\n",
    "model = PhonemeLangModel()\n",
    "model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01593ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
