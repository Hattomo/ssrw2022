{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb190232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from language_model import PhonemeLangModel\n",
    "from phoneme_dataset import PhonemeDataset, collate_fn, dataset_spliter, MaskedPhonemeDataset, PAD_NUM\n",
    "\n",
    "from torchvision import transforms\n",
    "from trainer_phoneme import Trainer, MaskedTrainer\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e623fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1000\n",
    "data_path = './data/ROHAN_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999126d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r') as f:\n",
    "    sentenses = f.readlines()\n",
    "datas = [s.replace('\\n', '').split()[1:] for s in sentenses]\n",
    "print(datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0c60801",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_path = 'data/phoneme_dict.json'\n",
    "with open(dict_path, 'r') as f:\n",
    "    phone_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2479ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_train, datas_valid, datas_test = dataset_spliter(datas)\n",
    "dataset_train = MaskedPhonemeDataset(phone_dict, datas_train)\n",
    "dataset_valid = MaskedPhonemeDataset(phone_dict, datas_valid)\n",
    "dataset_test  = MaskedPhonemeDataset(phone_dict, datas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ae7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              shuffle=True,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              collate_fn=collate_fn,\n",
    "                              drop_last=True)\n",
    "dataloader_valid = DataLoader(dataset_valid,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              collate_fn=collate_fn,\n",
    "                              drop_last=True)\n",
    "dataloader_test  = DataLoader(dataset_test,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              collate_fn=collate_fn,\n",
    "                              drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4ebd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './checkpoints_aoyama/lstm_lang_model.pth'\n",
    "model = PhonemeLangModel()\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aa0d619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainer = MaskedTrainer(model, dataloader_train, dataloader_valid, criterion, optimizer)\n",
    "trainer.train(EPOCHS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82767d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './checkpoints_aoyama/lstm_lang_model_ROHAN.pth'\n",
    "torch.save(model.to('cpu').state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54f52518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss_dict = {'train_loss': trainer.train_loss_list,\n",
    "             'valid_loss': trainer.valid_loss_list,\n",
    "             'train_acc': trainer.train_acc_list,\n",
    "             'valid_acc': trainer.valid_acc_list}\n",
    "df = pd.DataFrame(loss_dict)\n",
    "df.to_csv('./checkpoints_aoyama/lstm_lang_model_losses_ROHAN_fine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2fcb308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./checkpoints_aoyama/lstm_lang_model_losses_ROHAN_fine.csv')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax1 = plt.subplots()\n",
    "x = np.array([i for i in range(EPOCHS)])\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.plot(x, df['train_loss'], label='train_loss')\n",
    "ax1.plot(x, df['valid_loss'], label='valid_loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, df['train_acc'], label='train_acc')\n",
    "ax2.plot(x, df['valid_acc'], label='valid_acc')\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_ylabel('loss')\n",
    "ax2.set_ylabel('acc')\n",
    "plt.savefig('./graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6c4cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './checkpoints_aoyama/lstm_lang_model_ROHAN.pth'\n",
    "model = PhonemeLangModel()\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deb809c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_sentence(model, batch):\n",
    "    model.eval()\n",
    "    datas, labels = batch\n",
    "    datas = datas.to(model.device)\n",
    "    labels = labels.to(model.device)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        states = (torch.zeros(1, BATCH_SIZE, model.hidden_dim_encoder).to(model.device),\n",
    "                  torch.zeros(1, BATCH_SIZE, model.hidden_dim_encoder).to(model.device))\n",
    "        outputs, _ = model(datas, states)\n",
    "        for output, label in zip(outputs, labels):\n",
    "            output = torch.argmax(output, dim=1).tolist()\n",
    "            acc += accuracy_score(label.tolist(), output)\n",
    "            # print(acc)\n",
    "            pad_index = output.index(PAD_NUM) if PAD_NUM in output else False\n",
    "            if pad_index:\n",
    "                output = torch.Tensor(output[:pad_index]).to(device=model.device, dtype=torch.long)\n",
    "            # print(f'output: {output}')\n",
    "            # print(f'label : {label}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8a073e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for batch in tqdm(dataloader_test, total=len(dataloader_train)):\n",
    "    acc = generate_sentence(model, batch)\n",
    "    print(acc/len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14153a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ssrw')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "27b38671b9e3b46a502e099c5896e6c039d46db8b62e9fa59670fe1a871ef72c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
